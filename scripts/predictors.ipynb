{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0665d90d-5169-4c46-8393-84ac9cddbeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67493ba4-08b4-4034-8e68-d10b25173402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d4966-c4f4-48b8-b220-b432fc3aa034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = \"path/to/your/data/\"  # Update this to your data directory\n",
    "MODELS_DIR = \"saved_models/\"\n",
    "METRICS_DIR = \"metrics/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "def load_data(data_dir):\n",
    "    train_path = os.path.join(data_dir, \"sanitized_train.json\")\n",
    "    val_path = os.path.join(data_dir, \"sanitized_validate.json\")\n",
    "    test_path = os.path.join(data_dir, \"sanitized_test.json\")\n",
    "    \n",
    "    with open(train_path, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    with open(val_path, 'r') as f:\n",
    "        val_data = json.load(f)\n",
    "    \n",
    "    with open(test_path, 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Custom Dataset class\n",
    "class ResponseLengthDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512, task='regression', bin_size=50):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.task = task\n",
    "        self.bin_size = bin_size\n",
    "        \n",
    "        # Encode model names\n",
    "        self.models = list(set([item['model'] for item in data]))\n",
    "        self.model_encoder = {model: idx for idx, model in enumerate(self.models)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            item['prompt_text'],\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Extract features\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "        \n",
    "        # One-hot encode model\n",
    "        model_idx = self.model_encoder[item['model']]\n",
    "        model_tensor = torch.zeros(len(self.models))\n",
    "        model_tensor[model_idx] = 1\n",
    "        \n",
    "        if self.task == 'regression':\n",
    "            # Targets for regression\n",
    "            output_mean = item['output_mean']\n",
    "            output_std = item['output_std']\n",
    "            target = torch.tensor([output_mean, output_std], dtype=torch.float)\n",
    "            \n",
    "        else:  # Classification\n",
    "            # Get p99 percentile and convert to class\n",
    "            p99 = item['output_percentiles']['99']\n",
    "            p99_class = int(p99 // self.bin_size)\n",
    "            target = torch.tensor(p99_class, dtype=torch.long)\n",
    "            \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask, \n",
    "            'model': model_tensor,\n",
    "            'target': target\n",
    "        }\n",
    "\n",
    "# Model definitions\n",
    "class TextEmbeddingModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name=\"distilbert-base-uncased\"):\n",
    "        super(TextEmbeddingModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Use the CLS token representation as the text embedding\n",
    "        return outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "class RegressionPredictor(nn.Module):\n",
    "    def __init__(self, text_embedding_size, num_models, hidden_size=128):\n",
    "        super(RegressionPredictor, self).__init__()\n",
    "        self.text_encoder = TextEmbeddingModel()\n",
    "        text_embedding_size = self.text_encoder.hidden_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(text_embedding_size + num_models, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, 2)  # Output mean and std\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, model_enc):\n",
    "        text_embedding = self.text_encoder(input_ids, attention_mask)\n",
    "        combined = torch.cat((text_embedding, model_enc), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.relu(self.fc1(combined)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        output = self.fc3(x)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class ClassificationPredictor(nn.Module):\n",
    "    def __init__(self, text_embedding_size, num_models, num_classes, hidden_size=128):\n",
    "        super(ClassificationPredictor, self).__init__()\n",
    "        self.text_encoder = TextEmbeddingModel()\n",
    "        text_embedding_size = self.text_encoder.hidden_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(text_embedding_size + num_models, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, model_enc):\n",
    "        text_embedding = self.text_encoder(input_ids, attention_mask)\n",
    "        combined = torch.cat((text_embedding, model_enc), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.relu(self.fc1(combined)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        logits = self.fc3(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, task='regression'):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    metrics = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'epoch': []\n",
    "    }\n",
    "    \n",
    "    if task == 'regression':\n",
    "        metrics.update({\n",
    "            'train_mse': [],\n",
    "            'train_mae': [],\n",
    "            'val_mse': [],\n",
    "            'val_mae': []\n",
    "        })\n",
    "    else:  # classification\n",
    "        metrics.update({\n",
    "            'train_accuracy': [],\n",
    "            'train_f1': [],\n",
    "            'val_accuracy': [],\n",
    "            'val_f1': []\n",
    "        })\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            model_tensor = batch['model'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask, model_tensor)\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Store predictions and targets for metrics\n",
    "            if task == 'regression':\n",
    "                all_preds.extend(outputs.detach().cpu().numpy())\n",
    "                all_targets.extend(targets.detach().cpu().numpy())\n",
    "            else:  # classification\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                model_tensor = batch['model'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(input_ids, attention_mask, model_tensor)\n",
    "                \n",
    "                # Loss calculation\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Store predictions and targets for metrics\n",
    "                if task == 'regression':\n",
    "                    val_preds.extend(outputs.detach().cpu().numpy())\n",
    "                    val_targets.extend(targets.detach().cpu().numpy())\n",
    "                else:  # classification\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_preds.extend(predicted.cpu().numpy())\n",
    "                    val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Store losses for plotting\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Calculate and store metrics\n",
    "        metrics['train_loss'].append(avg_train_loss)\n",
    "        metrics['val_loss'].append(avg_val_loss)\n",
    "        metrics['epoch'].append(epoch + 1)\n",
    "        \n",
    "        if task == 'regression':\n",
    "            # Convert lists to numpy arrays for metric calculation\n",
    "            all_preds_np = np.array(all_preds)\n",
    "            all_targets_np = np.array(all_targets)\n",
    "            val_preds_np = np.array(val_preds)\n",
    "            val_targets_np = np.array(val_targets)\n",
    "            \n",
    "            # Calculate MSE and MAE for mean predictions (first column)\n",
    "            train_mse_mean = mean_squared_error(all_targets_np[:, 0], all_preds_np[:, 0])\n",
    "            train_mae_mean = mean_absolute_error(all_targets_np[:, 0], all_preds_np[:, 0])\n",
    "            val_mse_mean = mean_squared_error(val_targets_np[:, 0], val_preds_np[:, 0])\n",
    "            val_mae_mean = mean_absolute_error(val_targets_np[:, 0], val_preds_np[:, 0])\n",
    "            \n",
    "            metrics['train_mse'].append(train_mse_mean)\n",
    "            metrics['train_mae'].append(train_mae_mean)\n",
    "            metrics['val_mse'].append(val_mse_mean)\n",
    "            metrics['val_mae'].append(val_mae_mean)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "                  f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                  f\"Train MSE (mean): {train_mse_mean:.4f}, \"\n",
    "                  f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "                  f\"Val MSE (mean): {val_mse_mean:.4f}\")\n",
    "            \n",
    "        else:  # classification\n",
    "            train_acc = accuracy_score(all_targets, all_preds)\n",
    "            train_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "            val_acc = accuracy_score(val_targets, val_preds)\n",
    "            val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
    "            \n",
    "            metrics['train_accuracy'].append(train_acc)\n",
    "            metrics['train_f1'].append(train_f1)\n",
    "            metrics['val_accuracy'].append(val_acc)\n",
    "            metrics['val_f1'].append(val_f1)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "                  f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                  f\"Train Acc: {train_acc:.4f}, \"\n",
    "                  f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "                  f\"Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            print(f\"Saving best model with validation loss: {best_val_loss:.4f}\")\n",
    "            torch.save(model.state_dict(), os.path.join(MODELS_DIR, f\"best_{task}_model.pt\"))\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "# Evaluate the model on test set\n",
    "def evaluate_model(model, test_loader, criterion, task='regression'):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    test_preds = []\n",
    "    test_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            model_tensor = batch['model'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask, model_tensor)\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Store predictions and targets for metrics\n",
    "            if task == 'regression':\n",
    "                test_preds.extend(outputs.detach().cpu().numpy())\n",
    "                test_targets.extend(targets.detach().cpu().numpy())\n",
    "            else:  # classification\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_preds.extend(predicted.cpu().numpy())\n",
    "                test_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate average test loss\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    metrics = {'test_loss': avg_test_loss}\n",
    "    \n",
    "    if task == 'regression':\n",
    "        # Convert lists to numpy arrays for metric calculation\n",
    "        test_preds_np = np.array(test_preds)\n",
    "        test_targets_np = np.array(test_targets)\n",
    "        \n",
    "        # Calculate MSE and MAE for mean predictions (first column)\n",
    "        test_mse_mean = mean_squared_error(test_targets_np[:, 0], test_preds_np[:, 0])\n",
    "        test_mae_mean = mean_absolute_error(test_targets_np[:, 0], test_preds_np[:, 0])\n",
    "        \n",
    "        # Calculate MSE and MAE for std predictions (second column)\n",
    "        test_mse_std = mean_squared_error(test_targets_np[:, 1], test_preds_np[:, 1])\n",
    "        test_mae_std = mean_absolute_error(test_targets_np[:, 1], test_preds_np[:, 1])\n",
    "        \n",
    "        metrics.update({\n",
    "            'test_mse_mean': test_mse_mean,\n",
    "            'test_mae_mean': test_mae_mean,\n",
    "            'test_mse_std': test_mse_std,\n",
    "            'test_mae_std': test_mae_std\n",
    "        })\n",
    "        \n",
    "        print(f\"Test results - \"\n",
    "              f\"Loss: {avg_test_loss:.4f}, \"\n",
    "              f\"MSE (mean): {test_mse_mean:.4f}, \"\n",
    "              f\"MAE (mean): {test_mae_mean:.4f}, \"\n",
    "              f\"MSE (std): {test_mse_std:.4f}, \"\n",
    "              f\"MAE (std): {test_mae_std:.4f}\")\n",
    "        \n",
    "    else:  # classification\n",
    "        test_acc = accuracy_score(test_targets, test_preds)\n",
    "        test_f1 = f1_score(test_targets, test_preds, average='weighted')\n",
    "        \n",
    "        metrics.update({\n",
    "            'test_accuracy': test_acc,\n",
    "            'test_f1': test_f1\n",
    "        })\n",
    "        \n",
    "        print(f\"Test results - \"\n",
    "              f\"Loss: {avg_test_loss:.4f}, \"\n",
    "              f\"Accuracy: {test_acc:.4f}, \"\n",
    "              f\"F1 Score: {test_f1:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Plot metrics\n",
    "def plot_metrics(metrics, task='regression'):\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(metrics['epoch'], metrics['train_loss'], label='Train Loss')\n",
    "    plt.plot(metrics['epoch'], metrics['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{task.capitalize()} Model - Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    if task == 'regression':\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(metrics['epoch'], metrics['train_mse'], label='Train MSE')\n",
    "        plt.plot(metrics['epoch'], metrics['val_mse'], label='Validation MSE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MSE')\n",
    "        plt.title('Mean Squared Error (for Mean Prediction)')\n",
    "        plt.legend()\n",
    "    else:  # classification\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(metrics['epoch'], metrics['train_accuracy'], label='Train Accuracy')\n",
    "        plt.plot(metrics['epoch'], metrics['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(METRICS_DIR, f'{task}_training_metrics.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Main execution function\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    train_data, val_data, test_data = load_data(DATA_DIR)\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    \n",
    "    # Setup for regression task\n",
    "    print(\"\\nSetting up regression predictor...\")\n",
    "    train_dataset_reg = ResponseLengthDataset(train_data, tokenizer, task='regression')\n",
    "    val_dataset_reg = ResponseLengthDataset(val_data, tokenizer, task='regression')\n",
    "    test_dataset_reg = ResponseLengthDataset(test_data, tokenizer, task='regression')\n",
    "    \n",
    "    batch_size = 16\n",
    "    train_loader_reg = DataLoader(train_dataset_reg, batch_size=batch_size, shuffle=True)\n",
    "    val_loader_reg = DataLoader(val_dataset_reg, batch_size=batch_size)\n",
    "    test_loader_reg = DataLoader(test_dataset_reg, batch_size=batch_size)\n",
    "    \n",
    "    # Determine number of models\n",
    "    num_models = len(train_dataset_reg.models)\n",
    "    text_embedding_size = 768  # For distilbert\n",
    "    \n",
    "    # Initialize regression model\n",
    "    regression_model = RegressionPredictor(text_embedding_size, num_models).to(device)\n",
    "    \n",
    "    # Save model architecture info\n",
    "    with open(os.path.join(MODELS_DIR, 'regression_model_info.json'), 'w') as f:\n",
    "        json.dump({\n",
    "            'num_models': num_models,\n",
    "            'model_encoder': train_dataset_reg.model_encoder,\n",
    "            'models': train_dataset_reg.models\n",
    "        }, f)\n",
    "    \n",
    "    # Training parameters\n",
    "    regression_criterion = nn.MSELoss()\n",
    "    regression_optimizer = optim.Adam(regression_model.parameters(), lr=2e-5)\n",
    "    \n",
    "    # Train regression model\n",
    "    print(\"\\nTraining regression model...\")\n",
    "    trained_reg_model, reg_metrics = train_model(\n",
    "        regression_model, \n",
    "        train_loader_reg, \n",
    "        val_loader_reg, \n",
    "        regression_criterion, \n",
    "        regression_optimizer,\n",
    "        num_epochs=5,\n",
    "        task='regression'\n",
    "    )\n",
    "    \n",
    "    # Evaluate regression model\n",
    "    print(\"\\nEvaluating regression model on test set...\")\n",
    "    reg_test_metrics = evaluate_model(\n",
    "        trained_reg_model,\n",
    "        test_loader_reg,\n",
    "        regression_criterion,\n",
    "        task='regression'\n",
    "    )\n",
    "    \n",
    "    # Save regression metrics\n",
    "    with open(os.path.join(METRICS_DIR, 'regression_training_metrics.pkl'), 'wb') as f:\n",
    "        pickle.dump(reg_metrics, f)\n",
    "    \n",
    "    with open(os.path.join(METRICS_DIR, 'regression_test_metrics.json'), 'w') as f:\n",
    "        json.dump(reg_test_metrics, f)\n",
    "    \n",
    "    # Plot regression metrics\n",
    "    plot_metrics(reg_metrics, task='regression')\n",
    "    \n",
    "    # Setup for classification task\n",
    "    print(\"\\nSetting up classification predictor...\")\n",
    "    \n",
    "    # Define bin size\n",
    "    bin_size = 50\n",
    "    \n",
    "    # Find max p99 value to determine number of classes\n",
    "    max_p99 = 0\n",
    "    for dataset in [train_data, val_data, test_data]:\n",
    "        for item in dataset:\n",
    "            p99 = item['output_percentiles']['99']\n",
    "            max_p99 = max(max_p99, p99)\n",
    "    \n",
    "    num_classes = int(max_p99 // bin_size) + 1\n",
    "    print(f\"Maximum p99 value: {max_p99}, Number of classes: {num_classes}\")\n",
    "    \n",
    "    train_dataset_cls = ResponseLengthDataset(train_data, tokenizer, task='classification', bin_size=bin_size)\n",
    "    val_dataset_cls = ResponseLengthDataset(val_data, tokenizer, task='classification', bin_size=bin_size)\n",
    "    test_dataset_cls = ResponseLengthDataset(test_data, tokenizer, task='classification', bin_size=bin_size)\n",
    "    \n",
    "    train_loader_cls = DataLoader(train_dataset_cls, batch_size=batch_size, shuffle=True)\n",
    "    val_loader_cls = DataLoader(val_dataset_cls, batch_size=batch_size)\n",
    "    test_loader_cls = DataLoader(test_dataset_cls, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize classification model\n",
    "    classification_model = ClassificationPredictor(text_embedding_size, num_models, num_classes).to(device)\n",
    "    \n",
    "    # Save model architecture info\n",
    "    with open(os.path.join(MODELS_DIR, 'classification_model_info.json'), 'w') as f:\n",
    "        json.dump({\n",
    "            'num_models': num_models,\n",
    "            'num_classes': num_classes,\n",
    "            'bin_size': bin_size,\n",
    "            'model_encoder': train_dataset_cls.model_encoder,\n",
    "            'models': train_dataset_cls.models\n",
    "        }, f)\n",
    "    \n",
    "    # Training parameters\n",
    "    classification_criterion = nn.CrossEntropyLoss()\n",
    "    classification_optimizer = optim.Adam(classification_model.parameters(), lr=2e-5)\n",
    "    \n",
    "    # Train classification model\n",
    "    print(\"\\nTraining classification model...\")\n",
    "    trained_cls_model, cls_metrics = train_model(\n",
    "        classification_model, \n",
    "        train_loader_cls, \n",
    "        val_loader_cls, \n",
    "        classification_criterion, \n",
    "        classification_optimizer,\n",
    "        num_epochs=5,\n",
    "        task='classification'\n",
    "    )\n",
    "    \n",
    "    # Evaluate classification model\n",
    "    print(\"\\nEvaluating classification model on test set...\")\n",
    "    cls_test_metrics = evaluate_model(\n",
    "        trained_cls_model,\n",
    "        test_loader_cls,\n",
    "        classification_criterion,\n",
    "        task='classification'\n",
    "    )\n",
    "    \n",
    "    # Save classification metrics\n",
    "    with open(os.path.join(METRICS_DIR, 'classification_training_metrics.pkl'), 'wb') as f:\n",
    "        pickle.dump(cls_metrics, f)\n",
    "    \n",
    "    with open(os.path.join(METRICS_DIR, 'classification_test_metrics.json'), 'w') as f:\n",
    "        json.dump(cls_test_metrics, f)\n",
    "    \n",
    "    # Plot classification metrics\n",
    "    plot_metrics(cls_metrics, task='classification')\n",
    "    \n",
    "    print(\"\\nTraining and evaluation complete!\")\n",
    "    print(f\"Models saved to: {MODELS_DIR}\")\n",
    "    print(f\"Metrics saved to: {METRICS_DIR}\")\n",
    "\n",
    "# Inference functions\n",
    "def load_regression_model(model_path):\n",
    "    # Load model info\n",
    "    with open(os.path.join(MODELS_DIR, 'regression_model_info.json'), 'r') as f:\n",
    "        model_info = json.load(f)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = RegressionPredictor(768, model_info['num_models']).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    return model, model_info\n",
    "\n",
    "def load_classification_model(model_path):\n",
    "    # Load model info\n",
    "    with open(os.path.join(MODELS_DIR, 'classification_model_info.json'), 'r') as f:\n",
    "        model_info = json.load(f)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ClassificationPredictor(768, model_info['num_models'], model_info['num_classes']).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    return model, model_info\n",
    "\n",
    "def predict_response_length(prompt_text, model_name, task='regression'):\n",
    "    # Load appropriate model\n",
    "    if task == 'regression':\n",
    "        model_path = os.path.join(MODELS_DIR, 'best_regression_model.pt')\n",
    "        model, model_info = load_regression_model(model_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    else:  # classification\n",
    "        model_path = os.path.join(MODELS_DIR, 'best_classification_model.pt')\n",
    "        model, model_info = load_classification_model(model_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    \n",
    "    # Check if model_name exists in the training data\n",
    "    model_encoder = model_info['model_encoder']\n",
    "    if model_name not in model_encoder:\n",
    "        print(f\"Warning: Model '{model_name}' not found in training data. Using fallback.\")\n",
    "        model_name = list(model_encoder.keys())[0]\n",
    "    \n",
    "    # Prepare inputs\n",
    "    encoding = tokenizer(\n",
    "        prompt_text,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Prepare model one-hot encoding\n",
    "    model_tensor = torch.zeros(len(model_encoder)).to(device)\n",
    "    model_tensor[model_encoder[model_name]] = 1\n",
    "    model_tensor = model_tensor.unsqueeze(0)\n",
    "    \n",
    "    # Prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, model_tensor)\n",
    "        \n",
    "        if task == 'regression':\n",
    "            mean_pred, std_pred = output[0].cpu().numpy()\n",
    "            return {\n",
    "                'predicted_mean': mean_pred,\n",
    "                'predicted_std': std_pred\n",
    "            }\n",
    "        else:  # classification\n",
    "            _, predicted_class = torch.max(output, 1)\n",
    "            bin_size = model_info['bin_size']\n",
    "            lower_bound = predicted_class.item() * bin_size\n",
    "            upper_bound = (predicted_class.item() + 1) * bin_size\n",
    "            return {\n",
    "                'predicted_p99_class': predicted_class.item(),\n",
    "                'predicted_p99_range': f\"{lower_bound}-{upper_bound} tokens\"\n",
    "            }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    # Example usage of prediction\n",
    "    print(\"\\nExample predictions:\")\n",
    "    \n",
    "    example_prompt = \"Write a comprehensive essay about the impact of artificial intelligence on society.\"\n",
    "    example_model = \"gpt-3.5-turbo\"\n",
    "    \n",
    "    reg_prediction = predict_response_length(example_prompt, example_model, task='regression')\n",
    "    print(f\"Regression prediction: Expected response mean length: {reg_prediction['predicted_mean']:.2f} tokens, \"\n",
    "          f\"Expected std: {reg_prediction['predicted_std']:.2f} tokens\")\n",
    "    \n",
    "    cls_prediction = predict_response_length(example_prompt, example_model, task='classification')\n",
    "    print(f\"Classification prediction: P99 token length class: {cls_prediction['predicted_p99_class']}, \"\n",
    "          f\"Range: {cls_prediction['predicted_p99_range']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
